<p>Supervised learning tasks are divided into two types, classification and regression. In classification tasks, the machine learning model has to find the decision boundary between the class variables. For example, classifying whether a given image is of a star or a supernova.</p>

<p><img src="/img/wp-content/uploads/2019/01/classification-300x300.png" alt="" /></p>

<p><strong>Classification</strong></p>

<p><img src="/img/wp-content/uploads/2019/01/classification-boundary-300x300.png" alt="" /></p>

<p><strong>With decision boundary</strong></p>

<p style="text-align:center">
  Note: This is a toy example and the actual plots and parameters may vary.
</p>

<p>In regression tasks, the machine learning model has to predict continuous values such as stock prices. Here, the model needs to find the best fit curve that approximates the unknown mapping function.</p>

<p><img src="/img/wp-content/uploads/2019/01/stocks-300x300.png" alt="" /></p>

<p><strong>Stock Prices</strong></p>

<p><img src="/img/wp-content/uploads/2019/01/stocks-predicted-300x296.png" alt="" /></p>

<p><strong>Predicting continuous values</strong></p>

<p>In the following discussion, I will focus on the regression example, but the idea presented is applicable to classification tasks as well.</p>

<p>Consider the following data points for the task of predicting house prices.</p>

<p>Now, a curve can be fit onto the data which gives some prediction on the data.</p>

<p><img src="/img/wp-content/uploads/2019/01/house_prices-linear-1024x1024.png" alt="" /></p>

<p>However, we can come up with a better fit onto the data.</p>

<p><img src="/img/wp-content/uploads/2019/01/house_prices-good-1024x1024.png" alt="" /></p>

<p>And what about the following curve? It passes through all the points.</p>

<p><img src="/img/wp-content/uploads/2019/01/house_prices-overfit-1024x1024.png" alt="" /></p>

<p>Surely, this is the best curve, right? No! Even though it fits the data well, it does not <em>generalize well</em>. What do I mean by generalizing? Consider that that we now have access to more data points.</p>

<p><img src="/img/wp-content/uploads/2019/01/house_prices-overfit-unknown-1024x1024.png" alt="" /></p>

<p>This clearly does fit the new data. This model has internalized the training data. There is no guarantee that the data not yet observed will map to this equation. The prediction might be way off. What we need is a trade-off. Something that fits the original data and can predict the unknown data with realibility.</p>

<h2 id="overfitting">Overfitting</h2>

<blockquote>
  <p>When the model does not generalize well for new data but fits the training data too well, it is called overfitting.</p>
</blockquote>

<p><img src="/img/wp-content/uploads/2019/01/house_prices-overfit-1024x1024.png" alt="" /></p>

<h2 id="underfitting">Underfitting</h2>

<blockquote>
  <p>When the model does not generalize well and does not even fit the training data, it is called underfitting.</p>
</blockquote>

<p><img src="/img/wp-content/uploads/2019/01/house_prices-linear-1024x1024.png" alt="" /></p>

<p>Hey! You have reached the end ðŸ˜Ž. Thanks for reading.</p>

<p>I would appreciate if you leave a comment below. Your suggestions will help me improve.</p>

<p>Subscribe to stay updated and say Hi! to me on <a href="https://twitter.com/ashwinvaidya17">twitter</a> if you wish to.</p>
